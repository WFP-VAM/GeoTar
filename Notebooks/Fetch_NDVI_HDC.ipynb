{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c1631-6ad0-45f2-bf5a-9578446a97bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NDVI anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1fb52-128c-443c-8f06-4a9bcbe6078b",
   "metadata": {},
   "source": [
    "The first step is to load all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523e341-5490-45a5-bef7-1502b61d8550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.plugins\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "from IPython.display import HTML, display\n",
    "from pystac_client import Client\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import pathlib\n",
    "import json\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import rioxarray\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb90ff-e7e0-4261-a381-c50083845dd4",
   "metadata": {},
   "source": [
    "Now we need to configure and start a session in the datacube, to do this, we need to log-in using a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8294994-8979-4321-8c0e-d02d326b3a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = pathlib.Path().resolve().parent.parent\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862f00f-275d-4de8-80d5-73e1aaf67b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKEN_PATH = \"path to token\"\n",
    "HDC_STAC_URL= \"url\"\n",
    "\n",
    "import os\n",
    "def _get_hdc_stac_param_from_env():\n",
    "    \n",
    "    if \"JUPYTERHUB_USER\" in os.environ:\n",
    "    \n",
    "        signer = None\n",
    "        header = None\n",
    "        aws={}   # Get credentials for accessing S3 bucket \n",
    "\n",
    "    else:\n",
    "\n",
    "        def make_signer(fname=\"./tk.json\"):\n",
    "            \"\"\"\n",
    "            Loads token from file at fname, and returns a function patching request urls with said token\n",
    "            \"\"\"\n",
    "            tk = \"\"\n",
    "            with open(fname, \"rt\") as src:\n",
    "                tk = json.load(src)[\"tk\"]\n",
    "\n",
    "            def sign(url, _tk=tk):\n",
    "                signed = f\"{url}?{_tk}\"\n",
    "                return signed\n",
    "\n",
    "            return sign\n",
    "\n",
    "        signer = make_signer(TOKEN_PATH)\n",
    "        header = {\"origin\": \"https://wfp.org\"}\n",
    "        aws = None\n",
    "        \n",
    "    # Instantiate an API client pointing to the WFP HDC STAC API\n",
    "    hdc_stac_client = Client.open(HDC_STAC_URL, headers=header)\n",
    "    \n",
    "    # Set up GDAL/rasterio configuration.\n",
    "    configure_rio(cloud_defaults=True, verbose=True, aws=aws)\n",
    "        \n",
    "    return hdc_stac_client, signer\n",
    "\n",
    "\n",
    "#\n",
    "# STAC CLIENTS\n",
    "#\n",
    "\n",
    "hdc_stac_client, signer = _get_hdc_stac_param_from_env() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8033fd0-e88a-4108-9ffd-6aacb40c0d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask the user to select an option\n",
    "print(\"Please select the pilot area:\")\n",
    "print(\"1. COL\")\n",
    "print(\"2. CHAD\")\n",
    "print(\"3. IRAQ Dahuk\")\n",
    "print(\"4. IRAQ Najaf\")\n",
    "pilot = input()\n",
    "assert pilot in ['1', '2', '3', '4'], \"Invalid pilot area selected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02f0a4-2a0e-4f86-9cc9-31ee3ad07c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pilot == \"1\":\n",
    "    #input_shp = \"C:/Geotar/COL/geodata/Processed/Education/Education_facilities.shp\"\n",
    "    pilot_name = \"COL\"\n",
    "    mask_shp = \"C:/Geotar/COL/geodata/Processed/Mask/COL_mask.shp\"\n",
    "    period = \"2021-05-01/2022-01-31\"\n",
    "    #output = f\"C:/Geotar/COL/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Colombia\")\n",
    "elif pilot == \"2\":\n",
    "    pilot_name = \"CHAD\"\n",
    "    #input_shp = \"zip://C:/Geotar/CHAD/geodata/Processed/Education/hotosm_chad_education_facilities_points_shp.zip/hotosm_chad_education_facilities_points.shp\"\n",
    "    mask_shp = \"C:/Geotar/CHAD/geodata/Processed/Mask/Chad_mask.shp\"\n",
    "    period = \"2022-05-01/2023-01-31\"\n",
    "    #periodlta = \"1970-01-01/1970-12-31\"\n",
    "    #output = f\"C:/Geotar/CHAD/geodata/Processed/{res_folder}/dist_{res_folder}_\"+ out_name\n",
    "    print(\"You selected CHAD\")\n",
    "elif pilot == \"3\":\n",
    "    pilot_name = \"IRAQ_D\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_D/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = \"C:/Geotar/IRAQ_D/geodata/Processed/Mask/Dahuk_mask.shp\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #output = f\"C:/Geotar/IRAQ_D/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Dahuk\")\n",
    "elif pilot == \"4\":\n",
    "    pilot_name = \"IRAQ_N\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = \"C:/Geotar/IRAQ_N/geodata/Processed/Mask/Najaf_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Najaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89798d-0011-48d8-9dad-5d34600afc4d",
   "metadata": {},
   "source": [
    "The next step is to get the NDVI data from the data cube, to do so, we need to define the bounding box of the pilot area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4491de-3f96-4643-b4af-f0ff2a612502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the shapefiles\n",
    "area_shp = gpd.read_file(mask_shp)\n",
    "\n",
    "# Get the bounding box of the shapefile\n",
    "bbox = area_shp.total_bounds\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e6c11-935c-48fe-962e-f74df2100441",
   "metadata": {},
   "source": [
    "View the location of the bounding box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee4c2-1598-4a66-8c0f-478c7ae14e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a map centered at the center point of the polygon\n",
    "m = folium.Map(location=[bbox[1], bbox[0]], zoom_start=7)\n",
    "\n",
    "# Add a polygon to the map\n",
    "folium.Polygon(\n",
    "    [\n",
    "        [bbox[1], bbox[0]],\n",
    "        [bbox[1], bbox[2]],\n",
    "        [bbox[3], bbox[2]],\n",
    "        [bbox[3], bbox[0]],\n",
    "        [bbox[1], bbox[0]],\n",
    "    ],\n",
    "    color='red',\n",
    "    fill_color='red',\n",
    "    fill_opacity=0.2\n",
    ").add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d916a4-ebe5-41e3-9263-b5c0430f2263",
   "metadata": {},
   "source": [
    "Fetch the dekadal NDVI anomaly data from HDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b78f72-3c2e-4f37-bf29-a93269d5a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lt_dates = \"2002-07-01/2018-07-01\"\n",
    "query_ndvi_lta = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_viq_dekad\"], #mxd13a2_vim_dekad_lta\n",
    "    datetime= period).get_all_items()#1970-01-01T00:00:00Z/1970-12-31T00:00:00Z\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "ndvi_lta = stac_load(query_ndvi_lta, patch_url=signer, output_crs='EPSG:4326', resolution= res, bbox=bbox)\n",
    "ndvi_lta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d81914-c253-473d-be59-a02be6479be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the ndvi anomaly zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432814be-63c6-4288-be10-a5874860ad1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile = output_dir_zarr + \"/ndvi_an_stac.zarr\"\n",
    "ndvi_lta.to_zarr(outfile)\n",
    "print(f\"{outfile} saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa0081-4bc1-4de0-a2e5-0fc6af3877eb",
   "metadata": {},
   "source": [
    "Group the data by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1534c3-6b0f-4d8e-b106-3a09eddd27c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_ndvi_anom = ndvi_lta.groupby('time.month').mean('time')\n",
    "m_ndvi_lta_r = m_ndvi_anom #/100  this rescaling is not working\n",
    "m_ndvi_lta_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1424d-779d-4e60-b1b3-64737308d7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_ndvi_anom = m_ndvi_anom.mean(dim=[\"month\"])\n",
    "s_ndvi_anom\n",
    "image = s_ndvi_anom/100 # Rescaling applied here\n",
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation/season\"\n",
    "filename_s = f'{output_dir_s}/ndvi_a_m.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image.rio.to_raster(filename_s, driver='GTiff')\n",
    "print(f\"{filename_s} saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43d035-6c3f-43f2-ba63-49ad27922e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_ndvi_anom_max = m_ndvi_anom.max(dim=[\"month\"])\n",
    "s_ndvi_anom_max\n",
    "image_max = s_ndvi_anom_max/100 # Rescaling applied here\n",
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation/season\"\n",
    "filename_s_max = f'{output_dir_s}/ndvi_a_ma.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_max.rio.to_raster(filename_s_max, driver='GTiff')\n",
    "print(f\"{filename_s_max} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6af97f-5f47-4e87-9656-68d7674410ac",
   "metadata": {},
   "source": [
    "Exports a geotiff file for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d52cb-27a4-409a-aa1f-e234149fbc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(m_ndvi_lta_r.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    image = m_ndvi_lta_r.isel(month=i)/100 # Rescaling applied here\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/ndvi_a_{m_ndvi_lta_r.month.values[i]}.tif'\n",
    "\n",
    "    # write the data to a geotiff file\n",
    "    image.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f\"{filename} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e9599-bc19-4c01-ad50-3ccd8aa4a329",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch NDVI dekadal data for the period and pilot of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65273614-4375-4ca3-b172-3e03a26c1394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NDVI = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_vim_dekad\"],\n",
    "    datetime=period, #emulates the period of data cube files\n",
    ").get_all_items()\n",
    "\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "ndvi_stack = stac_load(NDVI, output_crs='EPSG:4326', resolution= res , patch_url=signer, bbox=bbox)\n",
    "#\n",
    "#ndvi_stack = stac_load(NDVI,  patch_url=signer, bbox=bbox)\n",
    "ndvi_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455ec54-9a0b-487a-9e17-0037689d636c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile_zarr = output_dir_zarr + \"/ndvi_stac.zarr\"\n",
    "print(f'path to zarr file: {outfile_zarr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a6eb7-95a6-4711-bcef-736cdf69d9a4",
   "metadata": {},
   "source": [
    "save the zarr file to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1c20e-eec1-4666-a4cc-988f3bff35e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save zarr file\n",
    "ndvi_stack.to_zarr(outfile_zarr)\n",
    "print(f\"{outfile_zarr} saved\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8354b32d-9fbe-4f44-a441-39eec0d57355",
   "metadata": {},
   "source": [
    "Open the ndvi dekadal from zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313e6a8-7027-4fda-a0a8-5b43090a6574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load zarr file containing NDVI dekadal data for the season\n",
    "ndvi_stack = xr.open_zarr(outfile_zarr)\n",
    "ndvi_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e5cfa-fec9-4fac-bcb8-72b13be41b60",
   "metadata": {},
   "source": [
    "Aggregate the dekadal NDVI by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dd393-912c-426d-98f9-a45175b145e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#m_ndvi = ndvi_stack.resample(time='1M').mean('time')\n",
    "m_ndvi = ndvi_stack.groupby('time.month').mean('time')\n",
    "m_ndvi = m_ndvi * 0.0001\n",
    "m_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cce18-a1fa-409d-8a97-8cf42bc06b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Aggregate the data by season\n",
    "ndvi_m_s = m_ndvi.mean(dim=[\"month\"])\n",
    "ndvi_m_s\n",
    "\n",
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/vegetation/season\"\n",
    "filename_m_s = f'{output_dir_s}/ndvi_m_s.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "ndvi_m_s.rio.to_raster(filename_m_s, driver='GTiff')\n",
    "print(f\"{filename_m_s} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4053011-7cc6-438e-bf97-2368e506cfed",
   "metadata": {
    "tags": []
   },
   "source": [
    "save the monthly ndvi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c4d20-d2a9-4fdb-8187-2818a4a80caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(m_ndvi.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    image_ndvi = m_ndvi.isel(month=i)\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/ndvi_{m_ndvi.month.values[i]}.tif'\n",
    "\n",
    "    # write the data to a geotiff file\n",
    "    image_ndvi.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f\"{filename} saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
