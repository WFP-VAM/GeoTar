{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3ffbe-765c-48e7-b4f6-735db8d63ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdal_array\n",
    "import numpy as np\n",
    "import os\n",
    "from terracatalogueclient import Catalogue \n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import requests\n",
    "from tqdm.auto import tqdm  # provides a progressbar\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490993c-693b-43e9-bb03-8c6ff9a1e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user to select an option\n",
    "print('Please select the pilot area:')\n",
    "print('0. GLOBAL')\n",
    "print('1. COL')\n",
    "print('2. CHAD')\n",
    "print('3. IRAQ Dahuk')\n",
    "print('4. IRAQ Najaf')\n",
    "print('5. IRAQ')\n",
    "print('6. LBN')\n",
    "print('7. VEN')\n",
    "print('9. SOM')\n",
    "print('10. BGD')\n",
    "\n",
    "pilot = input()\n",
    "assert pilot in ['0','1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], \"Invalid pilot area selected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0030b-e90c-41a0-846c-b22081699841",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pilot == \"0\":\n",
    "    #input_shp = \"C:/Geotar/COL/geodata/Processed/Education/Education_facilities.shp\"\n",
    "    pilot_name = \"GLOBAL\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/workspace/test_mask.shp\"\n",
    "    period = \"2021-05-01/2022-01-31\"\n",
    "    #output = f\"C:/Geotar/COL/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected GLobal\")\n",
    "elif pilot == \"1\":\n",
    "    #input_shp = \"C:/Geotar/COL/geodata/Processed/Education/Education_facilities.shp\"\n",
    "    pilot_name = \"COL\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/COL_mask.shp\"\n",
    "    period = \"2021-05-01/2022-01-31\"\n",
    "    #output = f\"C:/Geotar/COL/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Colombia\")\n",
    "elif pilot == \"2\":\n",
    "    pilot_name = \"CHAD\"\n",
    "    #input_shp = \"zip://C:/Geotar/CHAD/geodata/Processed/Education/hotosm_chad_education_facilities_points_shp.zip/hotosm_chad_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Chad_mask.shp\"\n",
    "    period = \"2022-05-01/2023-01-31\"\n",
    "    #periodlta = \"1970-01-01/1970-12-31\"\n",
    "    #output = f\"C:/Geotar/CHAD/geodata/Processed/{res_folder}/dist_{res_folder}_\"+ out_name\n",
    "    print(\"You selected CHAD\")\n",
    "elif pilot == \"3\":\n",
    "    pilot_name = \"IRAQ_D\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_D/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Dahuk_mask.shp\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #output = f\"C:/Geotar/IRAQ_D/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Dahuk\")\n",
    "elif pilot == \"4\":\n",
    "    pilot_name = \"IRAQ_N\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Najaf_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Najaf\")\n",
    "elif pilot == \"5\":\n",
    "    pilot_name = \"IRAQ\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Iraq_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ\")\n",
    "elif pilot == \"6\":\n",
    "    pilot_name = \"LBN\"\n",
    "    period = \"2021-10-01/2022-04-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/LBN_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Lebanon\")\n",
    "elif pilot == \"7\":\n",
    "    pilot_name = \"VEN\"\n",
    "    period = \"2023-01-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/VEN_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Venezuela\")\n",
    "elif pilot == \"8\":\n",
    "    pilot_name = \"AFG\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Afghanistan\")\n",
    "elif pilot == \"9\":\n",
    "    pilot_name = \"SOM\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Somalia\")\n",
    "elif pilot == \"10\":\n",
    "    pilot_name = \"BGD\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Bangladesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62abca-3e85-4738-bb86-ab769439bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_shp = gpd.read_file(mask_shp)\n",
    "\n",
    "# Get the bounding box of the shapefile\n",
    "bbox = area_shp.total_bounds\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3486b8-b985-4eae-a283-3de7b2619c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output folder path\n",
    "output_folder = f\"C:/Geotar/{pilot_name}/geodata/Processed/LandCover/tiles\"  \n",
    "# use current directory or set a different one to store downloaded files\n",
    "# create the directory if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f737255-81f2-496e-abc2-6e8d4e49202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get AOI geometry (select a country name)\n",
    "#country = 'Somalia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ffd21-e81b-4b70-a2e9-c0d3a2ba5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3_url_prefix = \"https://esa-worldcover.s3.eu-central-1.amazonaws.com\"\n",
    "\n",
    "# load natural earth low res shapefile\n",
    "#ne = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "#geom = ne[ne.name == country].iloc[0].geometry\n",
    "\n",
    "# Define the bounding box coordinates: [minx, miny, maxx, maxy]\n",
    "#bbox = [40.39407136, -1.92483662, 51.58562142, 13.63884234]\n",
    "\n",
    "# Create a GeoDataFrame with a single geometry representing the bounding box\n",
    "geom1 = gpd.GeoDataFrame(geometry=[box(bbox[0], bbox[1], bbox[2], bbox[3])], crs='EPSG:4326')\n",
    "geom1= geom1.geometry.iloc[0]\n",
    "\n",
    "# load worldcover grid\n",
    "url = f'{s3_url_prefix}/esa_worldcover_grid.geojson'\n",
    "#print(url)\n",
    "grid = gpd.read_file(url)\n",
    "\n",
    "# get grid tiles intersecting AOI\n",
    "tiles = grid[grid.intersects(geom1)]\n",
    "#tiles = gpd.overlay(grid, geom1, how='intersection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b8e6a-9404-431a-8179-7741b33b4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot both GeoDataFrames on the same figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the grid GeoDataFrame\n",
    "grid.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.5)\n",
    "\n",
    "# Create a GeoSeries containing the Polygon object\n",
    "geoms = gpd.GeoSeries([geom1])\n",
    "\n",
    "# Create a GeoDataFrame from the GeoSeries\n",
    "gdfplot = gpd.GeoDataFrame(geometry=geoms)\n",
    "\n",
    "# Plot the bounding box GeoDataFrame\n",
    "gdfplot.plot(ax=ax, color='red', alpha=0.5)\n",
    "\n",
    "# Customize the plot as needed\n",
    "ax.set_title(\"Overlay of GeoDataFrames\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db1784-05b3-4989-ba87-d6ce75df726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = 2021  # setting this to 2020 will download the v100 product instead\n",
    "\n",
    "# select version tag, based on the year\n",
    "version = {2020: 'v100',\n",
    "           2021: 'v200'}[year]\n",
    "\n",
    "for tile in tqdm(tiles.ll_tile):\n",
    "    url = f\"{s3_url_prefix}/{version}/{year}/map/ESA_WorldCover_10m_{year}_{version}_{tile}_Map.tif\"\n",
    "    out_fn = Path(output_folder) / Path(url).name\n",
    "    if not out_fn.exists():\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        with open(out_fn, 'wb') as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a0e63-7327-4e5b-9f0a-b86b4fddf07b",
   "metadata": {},
   "source": [
    "## Create reference raster from MODIS stored in HDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc19f4a-d8e0-4171-a8f8-530389ff14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import os\n",
    "\n",
    "TOKEN_PATH = \"C:/Users/oscar.bautista/OneDrive - World Food Programme/Scripts/tk.json\"\n",
    "HDC_STAC_URL= \"https://api.earthobservation.vam.wfp.org/stac/\"\n",
    "\n",
    "\n",
    "def _get_hdc_stac_param_from_env():\n",
    "    \n",
    "    if \"JUPYTERHUB_USER\" in os.environ:\n",
    "    \n",
    "        signer = None\n",
    "        header = None\n",
    "        aws={}   # Get credentials for accessing S3 bucket \n",
    "\n",
    "    else:\n",
    "\n",
    "        def make_signer(fname=\"./tk.json\"):\n",
    "            \"\"\"\n",
    "            Loads token from file at fname, and returns a function patching request urls with said token\n",
    "            \"\"\"\n",
    "            tk = \"\"\n",
    "            with open(fname, \"rt\") as src:\n",
    "                tk = json.load(src)[\"tk\"]\n",
    "\n",
    "            def sign(url, _tk=tk):\n",
    "                signed = f\"{url}?{_tk}\"\n",
    "                return signed\n",
    "\n",
    "            return sign\n",
    "\n",
    "        signer = make_signer(TOKEN_PATH)\n",
    "        header = {\"origin\": \"https://wfp.org\"}\n",
    "        aws = None\n",
    "        \n",
    "    # Instantiate an API client pointing to the WFP HDC STAC API\n",
    "    hdc_stac_client = Client.open(HDC_STAC_URL, headers=header)\n",
    "    \n",
    "    # Set up GDAL/rasterio configuration.\n",
    "    configure_rio(cloud_defaults=True, verbose=True, aws=aws)\n",
    "        \n",
    "    return hdc_stac_client, signer\n",
    "\n",
    "\n",
    "#\n",
    "# STAC CLIENTS\n",
    "#\n",
    "\n",
    "hdc_stac_client, signer = _get_hdc_stac_param_from_env() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3fcb5-d8ca-4168-9860-4ea0f81e91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "NDVI = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_vim_dekad\"],\n",
    "    datetime=\"2018-04-01/2018-04-30\", #emulates the period of data cube files\n",
    ").get_all_items()\n",
    "\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "ndvi_stack = stac_load(NDVI,  output_crs='EPSG:4326', resolution= res, patch_url=signer, bbox=bbox)\n",
    "ndvi_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7346bf-ed27-424d-be44-88bbce28b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ndvi_stack.mean(dim=[\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5992d-c50d-4372-b0c9-c075d1f87a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/mask\"\n",
    "filename_mod = f'{output_dir_s}/MODIS_mask.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "ndvi_m_s.rio.to_raster(filename_mod, driver='GTiff')\n",
    "print(f\"{filename_mod} saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d55b2e-9d54-457c-a822-a797cb301ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reference raster\n",
    "ref_tiff = filename_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c574b7-f3af-4b7f-9a3a-1f9cba0a6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WorldcovertoMODIS(dst_file,tiffs_path, ref_tif):\n",
    "    '''Function to mosaic the tiff files downloaded from the worldcover dataset AWS bucket\n",
    "    Inputs are:\n",
    "    1. the output tiff path\n",
    "    2. path to the tiled tif files\n",
    "    3. NDVI MODIS processed file\n",
    "    '''\n",
    "    # List all TIFF files in the working directory with complete file paths\n",
    "    tiffslist = [os.path.join(tiffs_path, f) for f in os.listdir(tiffs_path) if f.endswith('.tif')]\n",
    "    print(\"Files available: \")\n",
    "\n",
    "    for i in tiffslist:\n",
    "        print(i)\n",
    "        \n",
    "    def get_extent(ref_tif):\n",
    "        dataset = gdal.Open(ref_tif)\n",
    "        if dataset is None:\n",
    "            print(\"Failed to open the raster file.\")\n",
    "            return None\n",
    "\n",
    "        # Get geotransform information\n",
    "        geotransform = dataset.GetGeoTransform()\n",
    "        if geotransform is None:\n",
    "            print(\"Failed to get geotransform information.\")\n",
    "            return None\n",
    "\n",
    "        # Extract extent\n",
    "        minX = geotransform[0]\n",
    "        maxY = geotransform[3]\n",
    "        maxX = minX + geotransform[1] * dataset.RasterXSize\n",
    "        minY = maxY + geotransform[5] * dataset.RasterYSize\n",
    "    \n",
    "        # Extract x and y resolutions\n",
    "        xRes = abs(geotransform[1])\n",
    "        yRes = abs(geotransform[5])\n",
    "\n",
    "        return minX, minY, maxX, maxY, xRes, yRes\n",
    "    minX, minY, maxX, maxY, xRes, yRes = get_extent(ref_tif)\n",
    "    #keyword arguments that define extent and pixel size, these match the footprint og the modis ndvi data\n",
    "    kwargs={'format': 'GTiff',\n",
    "        'outputBounds':[minX, minY, maxX, maxY],\n",
    "        'outputBoundsSRS':'EPSG:4326',\n",
    "        'xRes':xRes,\n",
    "        'yRes':yRes,\n",
    "        'width':4984,\n",
    "        'height':6932,\n",
    "           }\n",
    "    #warp opetation\n",
    "    gdal.Warp(dst_file, tiffslist, **kwargs)\n",
    "    dst_file= None\n",
    "    print(mosaic_file_tif, \"processed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea816269-14b1-4f5c-a624-6a4c167a46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WorldcovertoMODIS(mosaic_file_tif, output_folder, ref_tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e783d2-84e4-4a35-a75c-11da5d69e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
