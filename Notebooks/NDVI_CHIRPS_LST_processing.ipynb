{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c1631-6ad0-45f2-bf5a-9578446a97bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NDVI anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45172d1c-1fd2-4773-afbe-60a26b071e62",
   "metadata": {},
   "source": [
    "This notebook can be used to load MODIS NDVI imagery from the humanitarian data cube (HDC). After validating the credentials to access the AWS repository, the data is fetched for the areas of interest (AOIs). AOIs  are pre-defined using shapefiles and their bounding boxes. These shapefiles must be prepared beforehand using a GIS software. Alternatively, the coordinates can be used to establish the top coordinates of the bounding box of the AOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1fb52-128c-443c-8f06-4a9bcbe6078b",
   "metadata": {},
   "source": [
    "The first step is to load all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523e341-5490-45a5-bef7-1502b61d8550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.plugins\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "from IPython.display import HTML, display\n",
    "from pystac_client import Client\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import pathlib\n",
    "import json\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import rioxarray\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb90ff-e7e0-4261-a381-c50083845dd4",
   "metadata": {},
   "source": [
    "Now we need to configure and start a session in the HDC, to do this, we need to log-in using a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8294994-8979-4321-8c0e-d02d326b3a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = pathlib.Path().resolve().parent.parent\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862f00f-275d-4de8-80d5-73e1aaf67b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKEN_PATH = \"C:/Users/oscar.bautista/OneDrive - World Food Programme/Scripts/tk.json\"\n",
    "HDC_STAC_URL= \"https://api.earthobservation.vam.wfp.org/stac/\"\n",
    "\n",
    "import os\n",
    "def _get_hdc_stac_param_from_env():\n",
    "    \n",
    "    if \"JUPYTERHUB_USER\" in os.environ:\n",
    "    \n",
    "        signer = None\n",
    "        header = None\n",
    "        aws={}   # Get credentials for accessing S3 bucket \n",
    "\n",
    "    else:\n",
    "\n",
    "        def make_signer(fname=\"./tk.json\"):\n",
    "            \"\"\"\n",
    "            Loads token from file at fname, and returns a function patching request urls with said token\n",
    "            \"\"\"\n",
    "            tk = \"\"\n",
    "            with open(fname, \"rt\") as src:\n",
    "                tk = json.load(src)[\"tk\"]\n",
    "\n",
    "            def sign(url, _tk=tk):\n",
    "                signed = f\"{url}?{_tk}\"\n",
    "                return signed\n",
    "\n",
    "            return sign\n",
    "\n",
    "        signer = make_signer(TOKEN_PATH)\n",
    "        header = {\"origin\": \"https://wfp.org\"}\n",
    "        aws = None\n",
    "        \n",
    "    # Instantiate an API client pointing to the WFP HDC STAC API\n",
    "    hdc_stac_client = Client.open(HDC_STAC_URL, headers=header)\n",
    "    \n",
    "    # Set up GDAL/rasterio configuration.\n",
    "    configure_rio(cloud_defaults=True, verbose=True, aws=aws)\n",
    "        \n",
    "    return hdc_stac_client, signer\n",
    "\n",
    "\n",
    "#\n",
    "# STAC CLIENTS\n",
    "#\n",
    "\n",
    "hdc_stac_client, signer = _get_hdc_stac_param_from_env() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8033fd0-e88a-4108-9ffd-6aacb40c0d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask the user to select an option\n",
    "print('Please select the pilot area:')\n",
    "print('0. GLOBAL')\n",
    "print('1. COL')\n",
    "print('2. CHAD')\n",
    "print('3. IRAQ Dahuk')\n",
    "print('4. IRAQ Najaf')\n",
    "print('5. IRAQ')\n",
    "print('6. LBN')\n",
    "print('7. VEN')\n",
    "print('9. SOM')\n",
    "print('10. BGD')\n",
    "\n",
    "pilot = input()\n",
    "assert pilot in ['0','1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], \"Invalid pilot area selected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02f0a4-2a0e-4f86-9cc9-31ee3ad07c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pilot == \"0\":\n",
    "    #input_shp = \"C:/Geotar/COL/geodata/Processed/Education/Education_facilities.shp\"\n",
    "    pilot_name = \"GLOBAL\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/workspace/test_mask.shp\"\n",
    "    period = \"2021-05-01/2022-01-31\"\n",
    "    #output = f\"C:/Geotar/COL/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected GLobal\")\n",
    "elif pilot == \"1\":\n",
    "    #input_shp = \"C:/Geotar/COL/geodata/Processed/Education/Education_facilities.shp\"\n",
    "    pilot_name = \"COL\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/COL_mask.shp\"\n",
    "    period = \"2021-05-01/2022-01-31\"\n",
    "    #output = f\"C:/Geotar/COL/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Colombia\")\n",
    "elif pilot == \"2\":\n",
    "    pilot_name = \"CHAD\"\n",
    "    #input_shp = \"zip://C:/Geotar/CHAD/geodata/Processed/Education/hotosm_chad_education_facilities_points_shp.zip/hotosm_chad_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Chad_mask.shp\"\n",
    "    period = \"2022-05-01/2023-01-31\"\n",
    "    #periodlta = \"1970-01-01/1970-12-31\"\n",
    "    #output = f\"C:/Geotar/CHAD/geodata/Processed/{res_folder}/dist_{res_folder}_\"+ out_name\n",
    "    print(\"You selected CHAD\")\n",
    "elif pilot == \"3\":\n",
    "    pilot_name = \"IRAQ_D\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_D/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Dahuk_mask.shp\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #output = f\"C:/Geotar/IRAQ_D/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Dahuk\")\n",
    "elif pilot == \"4\":\n",
    "    pilot_name = \"IRAQ_N\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Najaf_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ Najaf\")\n",
    "elif pilot == \"5\":\n",
    "    pilot_name = \"IRAQ\"\n",
    "    period = \"2021-11-01/2022-05-31\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/Iraq_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected IRAQ\")\n",
    "elif pilot == \"6\":\n",
    "    pilot_name = \"LBN\"\n",
    "    period = \"2021-10-01/2022-04-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/LBN_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Lebanon\")\n",
    "elif pilot == \"7\":\n",
    "    pilot_name = \"VEN\"\n",
    "    period = \"2023-01-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/VEN_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Venezuela\")\n",
    "elif pilot == \"8\":\n",
    "    pilot_name = \"AFG\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Afghanistan\")\n",
    "elif pilot == \"9\":\n",
    "    pilot_name = \"SOM\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Somalia\")\n",
    "elif pilot == \"10\":\n",
    "    pilot_name = \"BGD\"\n",
    "    period = \"2023-04-01/2023-07-30\"\n",
    "    #input_shp = \"zip://C:/Geotar/IRAQ_N/geodata/Raw/Education/hotosm_irq_education_facilities_points_shp.zip/hotosm_irq_education_facilities_points.shp\"\n",
    "    mask_shp = f\"C:/Geotar/{pilot_name}/geodata/Processed/Mask/{pilot_name}_mask.shp\"\n",
    "    #output = f\"C:/Geotar/IRAQ_N/geodata/Processed/{res_folder}/dist_\"+ out_name\n",
    "    print(\"You selected Bangladesh\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89798d-0011-48d8-9dad-5d34600afc4d",
   "metadata": {},
   "source": [
    "The next step is to get the NDVI data from the data cube, to do so, we need to define the bounding box of the pilot area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4491de-3f96-4643-b4af-f0ff2a612502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the shapefiles\n",
    "#Chad_shp = root/\"CHAD/Geodata/Raw/Boundaries/Villages_area.shp\"\n",
    "#Dahuk_shp = root/\"IRAQ/Geodata/Iraq_project/Dahuk_mask.shp\"\n",
    "#Najaf_shp = root/\"IRAQ/Geodata/Iraq_project/Najaf_mask.shp\"\n",
    "#Col_shp = root/\"COL/Geodata/\"\n",
    "\n",
    "area_shp = gpd.read_file(mask_shp)\n",
    "\n",
    "# Get the bounding box of the shapefile\n",
    "bbox = area_shp.total_bounds\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e6c11-935c-48fe-962e-f74df2100441",
   "metadata": {},
   "source": [
    "View the location of the bounding box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee4c2-1598-4a66-8c0f-478c7ae14e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the center of the map\n",
    "center = [(bbox[1]+bbox[3])/2, (bbox[0]+bbox[2])/2]\n",
    "# Create a map centered at the center point of the polygon\n",
    "m = folium.Map(location=center, zoom_start=4)\n",
    "\n",
    "# Add a polygon to the map\n",
    "folium.Polygon(\n",
    "    [\n",
    "        [bbox[1], bbox[0]],\n",
    "        [bbox[1], bbox[2]],\n",
    "        [bbox[3], bbox[2]],\n",
    "        [bbox[3], bbox[0]],\n",
    "        [bbox[1], bbox[0]],\n",
    "    ],\n",
    "    color='red',\n",
    "    fill_color='',\n",
    "    fill_opacity=0.2\n",
    ").add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e9599-bc19-4c01-ad50-3ccd8aa4a329",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetch NDVI dekadal data for the period and pilot of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a0873-4b02-45aa-9632-892e5881d548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NDVI = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_vim_dekad\"],\n",
    "    datetime=period, #emulates the period of data cube files\n",
    ").get_all_items()\n",
    "\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "ndvi_stack = stac_load(NDVI,  output_crs='EPSG:4326', resolution= res, patch_url=signer, bbox=bbox)\n",
    "#\n",
    "#ndvi_stack = stac_load(NDVI,  patch_url=signer, bbox=bbox)\n",
    "ndvi_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455ec54-9a0b-487a-9e17-0037689d636c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile_zarr = output_dir_zarr + \"/ndvi_stac.zarr\"\n",
    "# Delete the existing Zarr store if it exists\n",
    "if os.path.exists(outfile_zarr):\n",
    "    shutil.rmtree(outfile_zarr)\n",
    "print(f'path to zarr file: {outfile_zarr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a6eb7-95a6-4711-bcef-736cdf69d9a4",
   "metadata": {},
   "source": [
    "save the zarr file to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1c20e-eec1-4666-a4cc-988f3bff35e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save zarr file\n",
    "ndvi_stack.to_zarr(outfile_zarr)\n",
    "print(f\"{outfile_zarr} saved\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8354b32d-9fbe-4f44-a441-39eec0d57355",
   "metadata": {},
   "source": [
    "Open the ndvi dekadal from zarr file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313e6a8-7027-4fda-a0a8-5b43090a6574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "# outfile_zarr = output_dir_zarr + \"/ndvi_stac.zarr\"\n",
    "# #Load zarr file containing NDVI dekadal data for the season\n",
    "# ndvi_stack = xr.open_zarr(outfile_zarr)\n",
    "# ndvi_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e5cfa-fec9-4fac-bcb8-72b13be41b60",
   "metadata": {},
   "source": [
    "Aggregate the dekadal NDVI by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dd393-912c-426d-98f9-a45175b145e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#m_ndvi = ndvi_stack.resample(time='1M').mean('time')\n",
    "m_ndvi = ndvi_stack.groupby('time.month').mean('time')\n",
    "m_ndvi = m_ndvi * 0.0001\n",
    "m_ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd009f-ff27-416d-b163-f4fe5766d183",
   "metadata": {},
   "source": [
    "Mask out extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b9d3e-c291-41aa-807b-68fb10f8269d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_ndvi = xr.where(m_ndvi < -1, np.nan, m_ndvi)\n",
    "m_ndvi = xr.where(m_ndvi > 1, np.nan, m_ndvi)\n",
    "m_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b20052-42e4-4d48-98f9-7d8362e45fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Aggregate the data by season\n",
    "ndvi_m_s = m_ndvi.mean(dim=[\"month\"])\n",
    "ndvi_m_s\n",
    "\n",
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/vegetation/season\"\n",
    "filename_m_s = f'{output_dir_s}/ndvi_m_s.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "#ndvi_m_s.rio.to_raster(filename_m_s, driver='GTiff')\n",
    "print(f\"{filename_m_s} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c252fb-3429-41f6-a19e-8af86566984d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Mask NDVI using land cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19fe66-1779-42e3-8d72-b5e1dd945417",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = f\"C:/Geotar/{pilot_name}/geodata/Processed/LandCover/Worldcover_{pilot_name}.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1533a-6b75-41aa-b6f0-67e43e568484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_array = rioxarray.open_rasterio(tiff_path)\n",
    "#mask_array = mask_array.isel(band=0)\n",
    "mask_array = mask_array.squeeze(\"band\", drop=True)\n",
    "mask_array = mask_array.rename({'x': 'longitude','y': 'latitude'})\n",
    "mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded580e-4ef4-4560-b363-7305efeef573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_array = mask_array.transpose('latitude', 'longitude')\n",
    "mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbaaf6-4a5c-417e-bb1b-a1c638c2992f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latitude = ndvi_m_s['latitude'].values\n",
    "longitude = ndvi_m_s['longitude'].values\n",
    "# Convert mask_array to an xarray DataArray\n",
    "mask_dataarray = xr.DataArray(mask_array, coords={'latitude': latitude, 'longitude': longitude}, dims=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087cd4f-0e66-4589-b213-878da552e7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr.align(ndvi_m_s, mask_dataarray, join='exact')  # will raise a ValueError if not aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3edc3-bfa4-4ea6-881a-861dbe715933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a mask where conditions are not met and set to 0 where conditions are met\n",
    "ndvi_masked = xr.where((mask_dataarray == 40) | (mask_dataarray == 50), ndvi_m_s, 0)\n",
    "ndvi_masked = ndvi_masked.drop_vars('spatial_ref')\n",
    "ndvi_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea97f10-c9d3-4e79-9705-78d4471c5227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the masked ndvi data\n",
    "\n",
    "ndvi_masked.rio.to_raster(f'{output_dir_s}/ndvi_m_s.tif', driver='GTiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4053011-7cc6-438e-bf97-2368e506cfed",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the monthly ndvi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c4d20-d2a9-4fdb-8187-2818a4a80caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(m_ndvi.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    image_ndvi = m_ndvi.isel(month=i)\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/ndvi_{m_ndvi.month.values[i]}.tif'\n",
    "\n",
    "    # write the data to a geotiff file\n",
    "    image_ndvi.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f\"{filename} saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d916a4-ebe5-41e3-9263-b5c0430f2263",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetch the dekadal NDVI anomaly data from HDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8f132-90e5-4389-a384-879d34f3197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lt_dates = \"2002-07-01/2018-07-01\"\n",
    "query_ndvi_anom = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_viq_dekad\"], #mxd13a2_vim_dekad_lta\n",
    "    datetime= period).get_all_items()#1970-01-01T00:00:00Z/1970-12-31T00:00:00Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42897294-6478-4b73-a30c-2f64cf770dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "ndvi_anom = stac_load(query_ndvi_anom, patch_url=signer, output_crs='EPSG:4326', resolution= res, bbox=bbox, chunks ={})\n",
    "ndvi_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d81914-c253-473d-be59-a02be6479be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the ndvi anomaly zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432814be-63c6-4288-be10-a5874860ad1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile = output_dir_zarr + \"/ndvi_an_stac.zarr\"\n",
    "\n",
    "# Delete the existing Zarr store if it exists\n",
    "if os.path.exists(outfile):\n",
    "    shutil.rmtree(outfile)\n",
    "\n",
    "ndvi_anom.to_zarr(outfile)\n",
    "print(f\"{outfile} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d293c-ad80-4973-bfde-e1544f24b722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir_zarr = f\"C:/Geotar/{pilot_name}/geodata/zarr\"\n",
    "outfile_zarr = output_dir_zarr + \"/ndvi_an_stac.zarr\"\n",
    "#Load zarr file containing NDVI anomaly dekadal data for the season\n",
    "ndvi_anom = xr.open_zarr(outfile_zarr)\n",
    "ndvi_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df367cdb-3e0c-4c00-93bc-00ba72b4523b",
   "metadata": {},
   "source": [
    "Mask out no data/extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8696530-562e-439f-bd5d-1a8e90661e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_data = ndvi_anom['band'].isel(time=5)\n",
    "#plot_data.plot.hist()\n",
    "#ndvi_anom['band'].isnull()\n",
    "#ndvi_anom['band'].count(skipna = True)\n",
    "#ndvi_anom['band'].count(ndvi_anom['band'].isnull())\n",
    "#ndvi_anom.values()\n",
    "#ndvi_anom.dropna(dim=\"time\")\n",
    "#ndvi_anom.isnull()\n",
    "ndvi_anom_masked = xr.where(ndvi_anom < -150, np.nan, ndvi_anom)\n",
    "ndvi_anom_masked = xr.where(ndvi_anom_masked > 150, np.nan, ndvi_anom_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa0081-4bc1-4de0-a2e5-0fc6af3877eb",
   "metadata": {},
   "source": [
    "Group the data by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1534c3-6b0f-4d8e-b106-3a09eddd27c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_ndvi_anom = ndvi_anom_masked.groupby('time.month').mean('time')\n",
    "\n",
    "#m_ndvi_anom = ndvi_lta.groupby('time.month').mean('time')\n",
    "m_ndvi_lta_r = m_ndvi_anom #/100  this rescaling is not working\n",
    "m_ndvi_lta_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1424d-779d-4e60-b1b3-64737308d7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_ndvi_anom = m_ndvi_anom.mean(dim=[\"month\"])\n",
    "s_ndvi_anom\n",
    "image = s_ndvi_anom*0.01\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991e133-80ac-4a75-bec6-1b771e08b894",
   "metadata": {},
   "source": [
    "Mask NDVI anomaly using land cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971e656-cb81-4971-8673-0eef2d34d57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a mask where conditions are not met and set to 0 where conditions are met\n",
    "ndvi_anom_masked = xr.where((mask_dataarray == 40) | (mask_dataarray == 50), image, 0)\n",
    "ndvi_anom_masked = ndvi_anom_masked.drop_vars('spatial_ref')\n",
    "ndvi_anom_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6956a-3ab5-46f3-9c1d-f30d370e5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation/season\"\n",
    "\n",
    "filename_s = f'{output_dir_s}/ndvi_a_m.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "ndvi_anom_masked.rio.to_raster(filename_s, driver='GTiff', band_indices=[1] , mask_and_scale=True)\n",
    "print(f\"{filename_s} saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43d035-6c3f-43f2-ba63-49ad27922e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_ndvi_anom_max = m_ndvi_anom.max(dim=[\"month\"])\n",
    "s_ndvi_anom_max\n",
    "image_max = s_ndvi_anom_max*0.01\n",
    "output_dir_s = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation/season\"\n",
    "filename_s_max = f'{output_dir_s}/ndvi_a_ma.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_max.rio.to_raster(filename_s_max, driver='GTiff')\n",
    "print(f\"{filename_s_max} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6af97f-5f47-4e87-9656-68d7674410ac",
   "metadata": {},
   "source": [
    "Exports a geotiff file for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d52cb-27a4-409a-aa1f-e234149fbc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f\"C:/Geotar/{pilot_name}/geodata/Processed/Vegetation\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(m_ndvi_lta_r.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    image = m_ndvi_lta_r.isel(month=i)\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/ndvi_a_{m_ndvi_lta_r.month.values[i]}.tif'\n",
    "\n",
    "    # write the data to a geotiff file\n",
    "    image.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f\"{filename} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbeb288-97fb-4dac-977e-036ba8f72f57",
   "metadata": {},
   "source": [
    "# CHIRPS processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc674a-14d1-4e13-a8c4-c85ea136998e",
   "metadata": {},
   "source": [
    "The dates for the precipitation need to be adjusted, the idea is to account for a lag effect of a change the precipitation. The date shift was arbitrarily modified by one month in advance compared with the NDVI dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef65fd-be65-4403-9f19-e8f81d5a7daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# print the NDVI period:\n",
    "print(\"NDVI period:\", period)\n",
    "# Convert the period string to datetime objects\n",
    "start_date, end_date = period.split('/')\n",
    "start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Subtract one month from the start and end dates while preserving the day of the month\n",
    "modified_start_date = start_date - relativedelta(months=1)\n",
    "modified_end_date = end_date - relativedelta(months=1)\n",
    "\n",
    "# Format the modified dates back to the desired string format\n",
    "modified_period = modified_start_date.strftime(\"%Y-%m-%d\") + '/' + modified_end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Update the period variable with the modified period\n",
    "period = modified_period\n",
    "\n",
    "# Print the updated period\n",
    "print(\"CHIRPS period:\", period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9132cf-4fa3-4667-8a5a-862afb225141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=['mod13q1_vim_native'],\n",
    "    collections=['rfh_dekad'],\n",
    "    datetime= period, #'2022-01-01/2022-12-31'\n",
    ").get_all_items()\n",
    "\n",
    "res = 0.0022457882102988  #50.045454545Km #0.0022457882102988 # 250 or 0.01 for 1km\n",
    "\n",
    "CHIRPS_stac = stac_load(CHIRPS, output_crs='EPSG:4326', resolution= res , patch_url=signer, bbox=bbox)\n",
    "CHIRPS_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc750e2-a7a2-4d66-99c4-c1b7a38273aa",
   "metadata": {},
   "source": [
    "Paths to Save the zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246c11d-1a38-41c6-8136-c3a3b1ab40aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f'C:/Geotar/{pilot_name}/geodata/zarr'\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile = output_dir_zarr + '/CHIRPS_stac.zarr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1896b-e841-4869-bd5b-03aa02127a84",
   "metadata": {},
   "source": [
    "Save the zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8e48f-b87e-401b-ad83-1d1a36dbf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the existing Zarr store if it exists\n",
    "if os.path.exists(outfile):\n",
    "    shutil.rmtree(outfile)\n",
    "# save the zarr file\n",
    "CHIRPS_stac.to_zarr(outfile)\n",
    "print(f'{outfile} saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e70cf9-c5d3-4d9d-9e92-2b4100b41787",
   "metadata": {},
   "source": [
    "Load xarray from zarr file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc713bb2-c4ca-4fb1-95af-e54e11a987b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CHIRPS_stac = xr.open_zarr(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a81b7-e3b2-4770-a7a5-829743875055",
   "metadata": {},
   "source": [
    "Mask out no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed915bc2-a3ae-4218-999a-55af44ccd503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_stac = xr.where(CHIRPS_stac == -9999, np.nan, CHIRPS_stac)\n",
    "CHIRPS_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63298a8-a2bd-4500-b87f-399b440b0b88",
   "metadata": {},
   "source": [
    "Group CHIRPS data by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83ae0-7af5-4cf0-93b6-c37d38c83a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_m = CHIRPS_stac.groupby('time.month').sum('time', skipna=False)\n",
    "CHIRPS_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44860f52-0613-4ffa-8e47-0ef0cec01e7c",
   "metadata": {},
   "source": [
    "Creates the seasonal monthly mean precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36838f1a-f6dc-4635-9eb8-5cfa720451ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHIRPS_m_s = CHIRPS_m.mean(dim=['month'])\n",
    "CHIRPS_m_s\n",
    "\n",
    "output_dir_s = f'C:/Geotar/{pilot_name}/geodata/Processed/precipitation/season'\n",
    "filename_m_s = f'{output_dir_s}/rain_m_s.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "CHIRPS_m_s.rio.to_raster(filename_m_s, driver='GTiff')\n",
    "print(f'{filename_m_s} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2b71a-7ddb-4d2f-9eab-f7e177dbd55c",
   "metadata": {},
   "source": [
    "Creates the seasonal monthly sum precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbc36a-4a0e-4fcb-a710-1323381b746e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_s_s = CHIRPS_m.sum(dim=['month'])\n",
    "CHIRPS_s_s\n",
    "\n",
    "output_dir_s = f'C:/Geotar/{pilot_name}/geodata/Processed/precipitation/season'\n",
    "filename_s_s = f'{output_dir_s}/rain_s_s.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "CHIRPS_s_s.rio.to_raster(filename_s_s, driver='GTiff')\n",
    "print(f'{filename_s_s} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2cd03-fb7f-4366-9e01-2e56c825c1c9",
   "metadata": {},
   "source": [
    "Query and access the dekadal **CHIRPS precipitation anomaly** stored in the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f26bef-cf77-4727-a979-db71ae08cb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_an = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=['mod13q1_vim_native'],\n",
    "    collections=['rfq_dekad'],\n",
    "    datetime= period #'2022-01-01/2022-12-31',\n",
    ").get_all_items()\n",
    "#print(stac_items)\n",
    "\n",
    "CHIRPS_an_stac = stac_load(CHIRPS, output_crs='EPSG:4326', resolution= res , patch_url=signer, bbox=bbox)\n",
    "CHIRPS_an_stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a556d-3f5f-4374-83bb-584d9b10450f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir_zarr = f'C:/Geotar/{pilot_name}/geodata/zarr'\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "outfile = output_dir_zarr + '/CHIRPS_an_stac.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01d0a4-b64c-4985-952c-caac4b84d4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the existing Zarr store if it exists\n",
    "if os.path.exists(outfile):\n",
    "    shutil.rmtree(outfile)\n",
    "CHIRPS_an_stac.to_zarr(outfile)\n",
    "print(f'{outfile} saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e92e6e-8a4a-4509-bdbb-6a88982214f7",
   "metadata": {},
   "source": [
    "Load the xarray anomay from a zarr file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64968b-9330-4284-a5fc-9f4b6b331ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CHIRPS_an_stac = xr.open_zarr(outfile)\n",
    "#CHIRPS_an_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7839a-fb3b-4b79-bd30-d3ade323c48d",
   "metadata": {},
   "source": [
    "Mask out/set no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09867541-f81e-4a52-b938-9bb36ee00a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_an_stac = xr.where(CHIRPS_an_stac == -9999, np.nan, CHIRPS_an_stac)\n",
    "CHIRPS_an_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79be031-c8dd-48cd-9862-9739b3f2f8a1",
   "metadata": {},
   "source": [
    "Aggregate the dekadal Chirps anomaly data by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433dcd8-185d-40eb-a936-3df1eb0dac94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_an_m = CHIRPS_an_stac.groupby('time.month').mean('time')\n",
    "#rescale to have values from 0 to 1\n",
    "CHIRPS_an_m = CHIRPS_an_m/100\n",
    "CHIRPS_an_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9609d-2e2d-4e73-8b2a-637b03aa3780",
   "metadata": {},
   "source": [
    "Aggregate mean anomaly data by season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59794b8-c8a7-4ef2-89f4-977550bcbbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_an_s = CHIRPS_an_m.mean(dim=['month'])\n",
    "CHIRPS_an_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1a87c-fc56-4c8e-bcbb-c1167ac4c5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_an = CHIRPS_an_s\n",
    "output_dir_s = f'C:/Geotar/{pilot_name}/geodata/Processed/precipitation/season'\n",
    "filename_s = f'{output_dir_s}/rain_an_m.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_an.rio.to_raster(filename_s, driver='GTiff')\n",
    "print(f'{filename_s} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ae939-99f9-408e-959f-cffd49edf606",
   "metadata": {},
   "source": [
    "Agreggate anomaly max data season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfaf5cd-ad56-4875-a05c-d89e58c02d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHIRPS_an_s_max = CHIRPS_an_m.max(dim=['month'])\n",
    "CHIRPS_an_s_max\n",
    "image_an_m = CHIRPS_an_s_max # Rescaling applied here\n",
    "filename_s = f'{output_dir_s}/rain_an_ma.tif'\n",
    "# write the data to a geotiff file\n",
    "image_an_m.rio.to_raster(filename_s, driver='GTiff')\n",
    "print(f'{filename_s} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781c8e2-b389-435b-aa58-ce5e39ce6de4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Export CHIRPS Rainfall monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3396bd5-5e3c-4af8-bbb4-6bac0ed60068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f'C:/Geotar/{pilot_name}/geodata/Processed/Precipitation'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(CHIRPS_m.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    da = CHIRPS_m.isel(month=i)\n",
    "    # Set NaN as NoData\n",
    "    #print(\"The no data value is:\",da.rio.nodata)\n",
    "    \n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/rain_{CHIRPS_m.month.values[i]}.tif'\n",
    "    \n",
    "    # write the data to a geotiff file\n",
    "    da.rio.to_raster(filename)\n",
    "    print(f'{filename} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddd277-d0be-4dd6-b231-f9b25cd33755",
   "metadata": {
    "tags": []
   },
   "source": [
    "Export the monthly anomaly data to GeoTiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b664e9-e584-4cda-a957-adbdbe151add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f'C:/Geotar/{pilot_name}/geodata/Processed/Precipitation'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(CHIRPS_an_m.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    da = CHIRPS_an_m.isel(month=i)\n",
    "\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/rain_a_{CHIRPS_an_m.month.values[i]}.tif'\n",
    "    \n",
    "    # write the data to a geotiff file\n",
    "    da.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f'{filename} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102bf867-7206-49e3-b1a9-d72cfcac7c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Land Surface temperature processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439804a-9625-49a1-8bf4-78c66dc90afa",
   "metadata": {},
   "source": [
    "Need to readjust the dates of the period to have same dates as the NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefac901-c303-47b6-bcb4-7762ecde03b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the NDVI period:\n",
    "print(\"CHIRPS period:\", period)\n",
    "# Convert the period string to datetime objects\n",
    "start_date, end_date = period.split('/')\n",
    "start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# add one month from the start and end dates while preserving the day of the month\n",
    "modified_start_date = start_date + relativedelta(months=1)\n",
    "modified_end_date = end_date + relativedelta(months=1)\n",
    "\n",
    "# Format the modified dates back to the desired string format\n",
    "modified_period = modified_start_date.strftime(\"%Y-%m-%d\") + '/' + modified_end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Update the period variable with the modified period\n",
    "period = modified_period\n",
    "\n",
    "# Print the updated period\n",
    "print(\"LST period:\", period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96039bc-6611-44c5-9b7e-0bd8b9be28ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_query = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=['mod13q1_vim_native'],\n",
    "    collections=['myd11a2_txa_dekad'],\n",
    "    datetime= period #'2022-01-01/2022-12-31'\n",
    "                                ).get_all_items()\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "LST = stac_load(LST_query, output_crs='EPSG:4326', resolution= res , patch_url=signer, bbox=bbox)\n",
    "LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db018cb-835b-4cd6-9523-fa989b61ccc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir_zarr = f'C:/Geotar/{pilot_name}/geodata/zarr'\n",
    "outfile = output_dir_zarr + '/LST_stac.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70b594-4ae4-4e51-b5cd-2b55e697f084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "\n",
    "# Delete the existing Zarr file if it exists\n",
    "if os.path.exists(outfile):\n",
    "    shutil.rmtree(outfile)\n",
    "    \n",
    "LST.to_zarr(outfile)\n",
    "print(f'{outfile} saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61f90e-bef0-4320-aa78-1003fdaf797f",
   "metadata": {},
   "source": [
    "Load the Zarr file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d4294-c227-4aec-8ba0-47140da71080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LST = xr.open_zarr(outfile)\n",
    "#LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef5e60-52cb-435c-bdeb-0456f3d42296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_anom_query = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=['mod13q1_vim_native'],\n",
    "    collections=['myd11a2_txd_dekad'],\n",
    "    datetime= period #'2022-01-01/2022-12-31'\n",
    "                                ).get_all_items()\n",
    "res = 0.0022457882102988 # 250 or 0.01 for 1km\n",
    "LST_anom = stac_load(LST_anom_query, output_crs='EPSG:4326', resolution= res , patch_url=signer, bbox=bbox)\n",
    "LST_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2d4f4-8928-490c-a5e2-01d95bed338b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir_zarr = f'C:/Geotar/{pilot_name}/geodata/zarr'\n",
    "outfile = output_dir_zarr + '/LST_an_stac.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bcf3a-1932-43aa-a4ef-21d70a2a5215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "if not os.path.exists(output_dir_zarr):\n",
    "    os.makedirs(output_dir_zarr)\n",
    "\n",
    "# Delete the existing Zarr file if it exists\n",
    "if os.path.exists(outfile):\n",
    "    shutil.rmtree(outfile)\n",
    "\n",
    "LST_anom.to_zarr(outfile)\n",
    "print(f'{outfile} saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2266f3-66a0-4937-a838-e5706cec082b",
   "metadata": {},
   "source": [
    "Load xarray from zarr file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628f122-5aef-4fd7-bec0-51320a003fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_anom= xr.open_zarr(outfile)\n",
    "LST_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510d7f0-ff7d-429e-92ae-e6a56e11cc2d",
   "metadata": {},
   "source": [
    "Group LST and LST anomalies by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4cd71-9b48-47a8-92d4-72763e998951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group the lST data by month\n",
    "LST_m = LST.drop('tna')\n",
    "LST_m = LST_m.drop('spatial_ref')\n",
    "LST_m = LST_m.groupby('time.month').mean('time')\n",
    "LST_m = (LST_m * 0.02)- 273.15\n",
    "LST_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182d1fb-f451-4007-8eea-7af760d0c427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group the lST anomaly data by month\n",
    "LST_an_m = LST_anom.drop('tnd')\n",
    "LST_an_m = LST_an_m.drop('spatial_ref')\n",
    "LST_an_m = LST_an_m.groupby('time.month').mean('time')\n",
    "LST_an_m = LST_an_m  * 0.02\n",
    "#LST_an_m\n",
    "LST_an_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843b98e-ca8f-4529-981a-4fa1f955392e",
   "metadata": {},
   "source": [
    "Seasonal mean anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8fec7-80be-4675-a2ed-a0efe64ca648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_an_s = LST_an_m.mean(dim=['month'])\n",
    "\n",
    "image_an = LST_an_s/100 # Rescaling applied here\n",
    "output_dir_s = f'C:/Geotar/{pilot_name}/geodata/Processed/Temperature/season'\n",
    "filename_s = f'{output_dir_s}/LST_an_m.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_an.rio.to_raster(filename_s, driver='GTiff')\n",
    "print(f'{filename_s} saved successfully')\n",
    "#LST_an_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21576714-de58-4034-9ce4-ae8cdbcedd66",
   "metadata": {},
   "source": [
    "Seasonal max anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001f76f-29ca-40c8-80b0-1526ac49bac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_an_s_max = LST_an_m.max(dim=['month'])\n",
    "LST_an_s_max\n",
    "image_an_max = LST_an_s_max/100 # Rescaling applied here\n",
    "filename_s_max = f'{output_dir_s}/LST_an_ma.tif'\n",
    "# write the data to a geotiff file\n",
    "image_an_max.rio.to_raster(filename_s_max, driver='GTiff')\n",
    "print(f'{filename_s_max} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b37ff-6ef0-4928-8e4e-ef80202800d6",
   "metadata": {},
   "source": [
    "Export the mean seasonal temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3d7f9-aac3-4d69-b6a2-a44978282a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_s = LST_m.mean(dim=['month'])\n",
    "LST_s\n",
    "image_m = LST_s # Rescaling applied here\n",
    "output_dir_s = f'C:/Geotar/{pilot_name}/geodata/Processed/Temperature/season'\n",
    "filename_s = f'{output_dir_s}/LST_m.tif'\n",
    "if not os.path.exists(output_dir_s):\n",
    "    os.makedirs(output_dir_s)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_m.rio.to_raster(filename_s, driver='GTiff')\n",
    "print(f'{filename_s} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a8760-2a4a-4f4f-87d2-3a444c2df72f",
   "metadata": {},
   "source": [
    "Export the max seasonal temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b7119-465d-41d2-affe-1944a714315a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LST_s_max = LST_m.max(dim=['month'])\n",
    "LST_s_max\n",
    "image_max = LST_s_max # Rescaling applied here\n",
    "output_dir_s_max = f'C:/Geotar/{pilot_name}/geodata/Processed/Temperature/season'\n",
    "filename_s_max = f'{output_dir_s_max}/LST_ma.tif'\n",
    "if not os.path.exists(output_dir_s_max):\n",
    "    os.makedirs(output_dir_s_max)\n",
    "\n",
    "# write the data to a geotiff file\n",
    "image_max.rio.to_raster(filename_s_max, driver='GTiff')\n",
    "print(f'{filename_s_max} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b74b3-25d6-424c-b9cf-c01b7923eb0a",
   "metadata": {},
   "source": [
    "Export monthly LST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b7ad3-60fb-4d58-86d9-10b9cdad5b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LST_m = LST_m.drop('tnd')\n",
    "# create a directory to store the geotiff files\n",
    "output_dir = f'C:/Geotar/{pilot_name}/geodata/Processed/Temperature/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(LST_m.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    da = LST_m.isel(month=i)\n",
    "\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/LST_{LST_m.month.values[i]}.tif'\n",
    "    # write the data to a geotiff file\n",
    "    da.tda.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f'{filename} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e629be-0fe1-48aa-b7ee-98bd9fe29a6d",
   "metadata": {},
   "source": [
    "Export the monthly LST anomaly data to GeoTiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6eb18-f8f8-4747-91ac-b23fd6336c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a directory to store the geotiff files\n",
    "output_dir = f'C:/Geotar/{pilot_name}/geodata/Processed/Temperature'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop over all timesteps in the dataset\n",
    "for i in range(len(LST_an_m.month)):\n",
    "    # extract a single timestep as a DataArray\n",
    "    da = LST_an_m.isel(month=i)\n",
    "\n",
    "    # create a file path for the geotiff file\n",
    "    filename = f'{output_dir}/LST_an_{LST_an_m.month.values[i]}.tif'\n",
    "\n",
    "    # write the data to a geotiff file\n",
    "    da.rio.to_raster(filename, driver='GTiff')\n",
    "    print(f'{filename} saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a361595-b466-45d7-807f-e08ee5688aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old solution\n",
    "\n",
    "Results of the computed anomaly are strange, apparently ArcGIS is loading values from the replaced/deleted files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c0cdf-545b-4aed-b173-78b615cc0773",
   "metadata": {},
   "source": [
    "Fetch the long term NDVI data for the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8bf7e-db3f-46ed-a6af-dc7ca12de4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lt_dates = \"2002-07-01/2018-07-01\"\n",
    "query_ndvi_lt = hdc_stac_client.search(bbox=bbox,\n",
    "    #collections=[\"mod13q1_vim_native\"],\n",
    "    collections=[\"mxd13q1_vim_dekad\"], #mxd13a2_vim_dekad_lta\n",
    "    datetime= lt_dates).get_all_items()#1970-01-01T00:00:00Z/1970-12-31T00:00:00Z\n",
    "\n",
    "ndvi_lt = stac_load(query_ndvi_lt, patch_url=signer, output_crs='EPSG:4326', resolution= res, bbox=bbox)\n",
    "ndvi_lt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1f5cf-6171-4b0d-b559-46643b560ccb",
   "metadata": {},
   "source": [
    "Compute the NDVI average for each month along the entire time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109d5e8-76ea-408a-8588-0f761b6d91f5",
   "metadata": {},
   "source": [
    "Aggregate the dekadal NDVI long term average by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691e607-a36d-4d52-8fbe-2879a49c6441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_ndvi_lta = ndvi_lt.groupby('time.month').mean('time')\n",
    "m_ndvi_lta = m_ndvi_lta * 0.0001\n",
    "m_ndvi_lta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93893cb-bb1c-4e54-bd60-e6865b64363e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Calculate the anomaly by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccc398-0c54-4b71-958f-0ff557bc6aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndvi_an_m = (m_ndvi - m_ndvi_lta)\n",
    "ndvi_an_m = (m_ndvi - m_ndvi_lta)/m_ndvi_lta\n",
    "ndvi_an_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b51614-91ee-4748-b0fe-0c8b67db1efc",
   "metadata": {},
   "source": [
    "Compare the dimesions of NDVI time series dataset and the dimensions of the NDVI long term average. The dimension should be identical when computing the anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd67508-6b0f-4607-a366-6a7de670bd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ndvi_m.dims)\n",
    "print(ndvi_lta.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd7cd1-1b58-436a-952e-a3dd6f959597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dekad = 0\n",
    "current_data = m_ndvi_lta.band[dekad, :, :]\n",
    "current_data.plot(cmap='winter', figsize=[5,5])\n",
    "\n",
    "data = m_ndvi.band[dekad, :, :]\n",
    "data.plot(cmap='winter', figsize=[5,5])\n",
    "\n",
    "data = ndvi_anomaly.band[dekad, :, :]\n",
    "data.plot(cmap='winter', figsize=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904944e-f867-40ce-bd3b-b4e9a2eaf275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ndvi_anomaly(ndvi_stack, img_ndvi_lta, dekads, year):\n",
    "    \"\"\"\n",
    "    Computes the NDVI anomaly for the specified dekads.\n",
    "\n",
    "    Parameters:\n",
    "    ndvi_stack (xarray.DataArray): The NDVI stack.\n",
    "    img_ndvi_lta (xarray.DataArray): The long-term average NDVI image.\n",
    "    dekads (list): A list of integers representing the dekads to compute the anomaly for.\n",
    "\n",
    "    Returns:\n",
    "    anomalies (xarray.DataArray): An xarray DataArray containing the NDVI anomalies for each specified dekad.\n",
    "    \"\"\"\n",
    "    # Compute the anomalies for each specified dekad\n",
    "    anomalies = []\n",
    "    for dekad in dekads:\n",
    "        # Select the NDVI values for the specified year and dekad from both datasets\n",
    "        year = ndvi_stack.time.dt.year[0]\n",
    "        ndvi_year_dekad = ndvi_stack.sel(time=f'{year}-01-01T00:00:00', method='nearest').isel(time=(dekad-1)*3)\n",
    "        ndvi_lta_year_dekad = img_ndvi_lta.sel(time=f'1970-01-01T00:00:00', method='nearest').isel(time=dekad-1)\n",
    "\n",
    "        # Compute the dekad NDVI anomaly\n",
    "        anomaly = (ndvi_year_dekad - ndvi_lta_year_dekad) / ndvi_lta_year_dekad\n",
    "\n",
    "        # Add the anomaly to the list\n",
    "        anomalies.append(anomaly)\n",
    "\n",
    "    # Convert the list of anomalies into an xarray DataArray\n",
    "    anomalies = xr.concat(anomalies, dim='dekad')\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34cf1e-bee8-4b0e-aae8-06151985bd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdda8e-f769-43f6-be2f-3fe0d0302e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the mean of all pixels\n",
    "ndvi_lta_mean = m_ndvi_lta_r.mean(dim=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Plot the time series of the mean NDVI anomaly\n",
    "fig, ax = plt.subplots()\n",
    "ndvi_lta_mean.band.plot(ax=ax)\n",
    "ax.set_ylabel('Mean NDVI anomaly')\n",
    "ax.set_xlabel('Time')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa2447-cb99-4cab-a995-f45281e7cf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','K','M','G','T','P','E','Z']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21ca7d-fe21-49ff-b3ad-7bd6995fd873",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save and load xarrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b480d-618e-4139-8509-c5a0a860dba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_zarr = f\"C:/Geotar/{pilot_name}/geodata/workspace/nvdi.zarr\"\n",
    "m_ndvi_lta.to_zarr(output_zarr)\n",
    "print(f'zarr file saved on {output_zarr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5daa9d-dee6-408e-8301-efa0be0d410c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x= xr.open_zarr(f'C:/Geotar/{pilot_name}/geodata/workspace/nvdi.zarr')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d6f0e-03e1-4008-a407-dc1eda3cbf42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
